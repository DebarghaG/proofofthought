<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Debargha Ganguly" /><link rel="canonical" href="https://debarghaG.github.io/proofofthought/benchmarks/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Benchmarks - ProofOfThought</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Benchmarks";
        var mkdocs_page_input_path = "benchmarks.md";
        var mkdocs_page_url = "/proofofthought/benchmarks/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/json.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/bash.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> ProofOfThought
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../foreword/">Foreword</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../installation/">Installation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../dsl-specification/">DSL Specification</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../api-reference/">API Reference</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../backends/">Backends</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../examples/">Examples</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">Benchmarks</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#methodology">Methodology</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#results">Results</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#dataset-characteristics">Dataset Characteristics</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#prontoqa">ProntoQA</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#folio">FOLIO</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#proofwriter">ProofWriter</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#conditionalqa">ConditionalQA</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#strategyqa">StrategyQA</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#analysis">Analysis</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#accuracy-summary">Accuracy Summary</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#success-rate-summary">Success Rate Summary</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#failure-modes">Failure Modes</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#reproducing-results">Reproducing Results</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#full-benchmark-suite">Full benchmark suite</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#single-benchmark">Single benchmark</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#custom-evaluation">Custom evaluation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#dataset-sources">Dataset Sources</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#implementation-notes">Implementation Notes</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#parallel-processing">Parallel Processing</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#caching">Caching</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#timeout-handling">Timeout Handling</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../postprocessors/">Postprocessors</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">ProofOfThought</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Benchmarks</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/debarghaG/proofofthought/edit/main/docs/benchmarks.md">Edit on debarghaG/proofofthought</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="benchmarks">Benchmarks<a class="headerlink" href="#benchmarks" title="Permanent link">&para;</a></h1>
<p>This page presents evaluation results on 5 logical reasoning datasets using Azure GPT-5.</p>
<h2 id="methodology">Methodology<a class="headerlink" href="#methodology" title="Permanent link">&para;</a></h2>
<p>The evaluation follows a consistent methodology across all datasets.</p>
<p><strong>Model:</strong> Azure GPT-5 deployment</p>
<p><strong>Configuration:</strong>
- <code>max_attempts=3</code> (retry with error feedback)
- <code>verify_timeout=10000ms</code>
- <code>optimize_timeout=100000ms</code> (JSON backend only)
- <code>num_workers=10</code> (ThreadPoolExecutor for parallel processing)</p>
<p><strong>Metrics</strong> (computed via <code>sklearn.metrics</code>):</p>
<ul>
<li><strong>Accuracy:</strong> <code>accuracy_score(y_true, y_pred)</code></li>
<li><strong>Precision:</strong> <code>precision_score(y_true, y_pred, zero_division=0)</code></li>
<li><strong>Recall:</strong> <code>recall_score(y_true, y_pred, zero_division=0)</code></li>
<li><strong>F1:</strong> <code>2 * (precision * recall) / (precision + recall)</code></li>
<li><strong>Success Rate:</strong> <code>(total - failed) / total</code></li>
</ul>
<p><strong>Execution:</strong> The <code>experiments_pipeline.py</code> script runs all benchmarks sequentially, modifying the <code>BACKEND</code> variable in each <code>benchmark/bench_*.py</code> script via regex substitution.</p>
<h2 id="results">Results<a class="headerlink" href="#results" title="Permanent link">&para;</a></h2>
<p>Results from the most recent benchmark run.</p>
<p><strong>Last Updated:</strong> 2025-10-16 18:14:07</p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Backend</th>
<th>Samples</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1 Score</th>
<th>Success Rate</th>
</tr>
</thead>
<tbody>
<tr>
<td>ProntoQA</td>
<td>SMT2</td>
<td>100</td>
<td>100.00%</td>
<td>1.0000</td>
<td>1.0000</td>
<td>1.0000</td>
<td>100.00%</td>
</tr>
<tr>
<td>FOLIO</td>
<td>SMT2</td>
<td>100</td>
<td>69.00%</td>
<td>0.6949</td>
<td>0.7736</td>
<td>0.7321</td>
<td>99.00%</td>
</tr>
<tr>
<td>ProofWriter</td>
<td>SMT2</td>
<td>96</td>
<td>98.96%</td>
<td>1.0000</td>
<td>1.0000</td>
<td>1.0000</td>
<td>98.96%</td>
</tr>
<tr>
<td>ConditionalQA</td>
<td>SMT2</td>
<td>100</td>
<td>83.00%</td>
<td>0.9375</td>
<td>0.8219</td>
<td>0.8759</td>
<td>100.00%</td>
</tr>
<tr>
<td>StrategyQA</td>
<td>SMT2</td>
<td>100</td>
<td>84.00%</td>
<td>0.8205</td>
<td>0.7805</td>
<td>0.8000</td>
<td>100.00%</td>
</tr>
<tr>
<td>ProntoQA</td>
<td>JSON</td>
<td>100</td>
<td>99.00%</td>
<td>1.0000</td>
<td>0.9815</td>
<td>0.9907</td>
<td>100.00%</td>
</tr>
<tr>
<td>FOLIO</td>
<td>JSON</td>
<td>100</td>
<td>76.00%</td>
<td>0.7619</td>
<td>0.9412</td>
<td>0.8421</td>
<td>94.00%</td>
</tr>
<tr>
<td>ProofWriter</td>
<td>JSON</td>
<td>96</td>
<td>95.83%</td>
<td>1.0000</td>
<td>1.0000</td>
<td>1.0000</td>
<td>95.83%</td>
</tr>
<tr>
<td>ConditionalQA</td>
<td>JSON</td>
<td>100</td>
<td>76.00%</td>
<td>0.9180</td>
<td>0.8750</td>
<td>0.8960</td>
<td>89.00%</td>
</tr>
<tr>
<td>StrategyQA</td>
<td>JSON</td>
<td>100</td>
<td>68.00%</td>
<td>0.7500</td>
<td>0.7895</td>
<td>0.7692</td>
<td>86.00%</td>
</tr>
</tbody>
</table>
<h2 id="dataset-characteristics">Dataset Characteristics<a class="headerlink" href="#dataset-characteristics" title="Permanent link">&para;</a></h2>
<p>Each dataset tests different aspects of logical reasoning.</p>
<h3 id="prontoqa">ProntoQA<a class="headerlink" href="#prontoqa" title="Permanent link">&para;</a></h3>
<p>ProntoQA features synthetic first-order logic problems with deterministic inference.</p>
<p><strong>Example:</strong></p>
<div class="codehilite"><pre><span></span><code>Facts: &quot;Stella is a lion. All lions are brown.&quot;
Question: &quot;Is Stella brown?&quot;
Answer: True
</code></pre></div>

<p><strong>Performance:</strong></p>
<ul>
<li>SMT2: 100% (100/100)</li>
<li>JSON: 99% (99/100)</li>
</ul>
<p>Both backends achieve near-perfect results, making this the simplest dataset in the benchmark suite.</p>
<h3 id="folio">FOLIO<a class="headerlink" href="#folio" title="Permanent link">&para;</a></h3>
<p>FOLIO presents first-order logic problems derived from Wikipedia articles.</p>
<p><strong>Characteristics:</strong> Features complex nested quantifiers and longer inference chains.</p>
<p><strong>Performance:</strong></p>
<ul>
<li>SMT2: 69% (69/100)</li>
<li>JSON: 76% (76/100)</li>
</ul>
<p>JSON outperforms SMT2 by 7% on this dataset, which is the most challenging in the suite. However, JSON's lower success rate (94% vs 99%) indicates greater difficulty in program generation.</p>
<h3 id="proofwriter">ProofWriter<a class="headerlink" href="#proofwriter" title="Permanent link">&para;</a></h3>
<p>ProofWriter tests deductive reasoning over explicit facts and rules.</p>
<p><strong>Example:</strong></p>
<div class="codehilite"><pre><span></span><code>Facts: &quot;The bear is red. If something is red, then it is kind.&quot;
Question: &quot;Is the bear kind?&quot;
Answer: True
</code></pre></div>

<p><strong>Performance:</strong></p>
<ul>
<li>SMT2: 98.96% (95/96)</li>
<li>JSON: 95.83% (92/96)</li>
</ul>
<p>Both backends achieve high accuracy on this dataset, with SMT2 holding a slight 3% edge.</p>
<h3 id="conditionalqa">ConditionalQA<a class="headerlink" href="#conditionalqa" title="Permanent link">&para;</a></h3>
<p>ConditionalQA focuses on conditional reasoning with if-then statements.</p>
<p><strong>Performance:</strong></p>
<ul>
<li>SMT2: 83% (83/100)</li>
<li>JSON: 76% (76/100)</li>
</ul>
<p>SMT2 demonstrates better accuracy (+7%) and also achieves a higher success rate (100% vs 89%).</p>
<h3 id="strategyqa">StrategyQA<a class="headerlink" href="#strategyqa" title="Permanent link">&para;</a></h3>
<p>StrategyQA tests multi-hop reasoning that requires implicit world knowledge.</p>
<p><strong>Example:</strong></p>
<div class="codehilite"><pre><span></span><code>Question: &quot;Would a vegetarian eat a burger made of plants?&quot;
Answer: True (requires knowing: vegetarians avoid meat, plant burgers have no meat)
</code></pre></div>

<p><strong>Performance:</strong></p>
<ul>
<li>SMT2: 84% (84/100)</li>
<li>JSON: 68% (68/100)</li>
</ul>
<p>This dataset shows the largest performance gap, with SMT2 leading by 16%. Both backends achieve good success rates of 100% and 86% respectively.</p>
<h2 id="analysis">Analysis<a class="headerlink" href="#analysis" title="Permanent link">&para;</a></h2>
<h3 id="accuracy-summary">Accuracy Summary<a class="headerlink" href="#accuracy-summary" title="Permanent link">&para;</a></h3>
<p>Aggregating results across all datasets:</p>
<ul>
<li><strong>SMT2:</strong> 86.8% average accuracy</li>
<li><strong>JSON:</strong> 82.8% average accuracy</li>
</ul>
<p>SMT2 proves superior on 4 out of 5 datasets, with FOLIO being the exception where JSON leads by 7%.</p>
<h3 id="success-rate-summary">Success Rate Summary<a class="headerlink" href="#success-rate-summary" title="Permanent link">&para;</a></h3>
<p>The success rate measures program generation and execution reliability:</p>
<ul>
<li><strong>SMT2:</strong> 99.4% average (range: 98.96-100%)</li>
<li><strong>JSON:</strong> 92.8% average (range: 86-100%)</li>
</ul>
<p>SMT2 demonstrates more reliable program generation and execution overall. JSON's higher success rate variance indicates LLM generation challenges on certain datasets.</p>
<h3 id="failure-modes">Failure Modes<a class="headerlink" href="#failure-modes" title="Permanent link">&para;</a></h3>
<p>Understanding failure modes helps identify areas for improvement.</p>
<p><strong>SMT2 failures:</strong></p>
<ul>
<li>Program extraction from markdown: regex mismatch</li>
<li>Z3 subprocess timeout (rare with 10s limit)</li>
<li>Invalid SMT-LIB syntax (caught by Z3 parser)</li>
</ul>
<p><strong>JSON failures:</strong></p>
<ul>
<li>JSON parsing errors after extraction</li>
<li>Invalid sort references (e.g., undefined <code>Person</code> sort)</li>
<li>Expression evaluation errors in <code>ExpressionParser.parse_expression()</code></li>
<li>Z3 Python API exceptions</li>
</ul>
<h2 id="reproducing-results">Reproducing Results<a class="headerlink" href="#reproducing-results" title="Permanent link">&para;</a></h2>
<h3 id="full-benchmark-suite">Full benchmark suite<a class="headerlink" href="#full-benchmark-suite" title="Permanent link">&para;</a></h3>
<p>To run the complete benchmark suite:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>experiments_pipeline.py
</code></pre></div>

<p>This generates:</p>
<ul>
<li><code>results/benchmark_results.json</code> - Raw metrics data</li>
<li><code>results/benchmark_results.md</code> - Formatted markdown table</li>
<li>Updates <code>README.md</code> between <code>&lt;!-- BENCHMARK_RESULTS_START/END --&gt;</code> markers</li>
</ul>
<h3 id="single-benchmark">Single benchmark<a class="headerlink" href="#single-benchmark" title="Permanent link">&para;</a></h3>
<p>To run just one benchmark:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>benchmark/bench_strategyqa.py
</code></pre></div>

<p>You'll need to modify the <code>BACKEND</code> variable in the script to either <code>smt2</code> or <code>json</code>.</p>
<h3 id="custom-evaluation">Custom evaluation<a class="headerlink" href="#custom-evaluation" title="Permanent link">&para;</a></h3>
<p>For custom evaluation on your own dataset:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">utils.azure_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_client_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">z3adapter.reasoning</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProofOfThought</span><span class="p">,</span> <span class="n">EvaluationPipeline</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">get_client_config</span><span class="p">()</span>
<span class="n">pot</span> <span class="o">=</span> <span class="n">ProofOfThought</span><span class="p">(</span><span class="n">llm_client</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;llm_client&quot;</span><span class="p">],</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;smt2&quot;</span><span class="p">)</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">EvaluationPipeline</span><span class="p">(</span><span class="n">proof_of_thought</span><span class="o">=</span><span class="n">pot</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;data/strategyQA_train.json&quot;</span><span class="p">,</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">100</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="dataset-sources">Dataset Sources<a class="headerlink" href="#dataset-sources" title="Permanent link">&para;</a></h2>
<p>The benchmark datasets are located in the <code>data/</code> directory:</p>
<ul>
<li><strong>ProntoQA:</strong> <code>data/prontoqa_test.json</code></li>
<li><strong>FOLIO:</strong> <code>data/folio_test.json</code></li>
<li><strong>ProofWriter:</strong> <code>data/proof_writer_test.json</code></li>
<li><strong>ConditionalQA:</strong> <code>data/conditionalQA_test.json</code></li>
<li><strong>StrategyQA:</strong> <code>data/strategyQA_train.json</code></li>
</ul>
<p>All datasets follow the same format: JSON arrays with <code>question</code> and <code>answer</code> fields (boolean values).</p>
<h2 id="implementation-notes">Implementation Notes<a class="headerlink" href="#implementation-notes" title="Permanent link">&para;</a></h2>
<h3 id="parallel-processing">Parallel Processing<a class="headerlink" href="#parallel-processing" title="Permanent link">&para;</a></h3>
<p>Benchmark scripts use <code>num_workers=10</code> with <code>ThreadPoolExecutor</code> for parallel processing. Note that <code>ProcessPoolExecutor</code> cannot be used due to ProofOfThought being unpicklable.</p>
<h3 id="caching">Caching<a class="headerlink" href="#caching" title="Permanent link">&para;</a></h3>
<p>Setting <code>skip_existing=True</code> enables resumption of interrupted runs. Results are cached as:</p>
<ul>
<li><code>output/{backend}_evaluation_{dataset}/{sample_id}_result.json</code></li>
<li><code>output/{backend}_programs_{dataset}/{sample_id}_program.{ext}</code></li>
</ul>
<h3 id="timeout-handling">Timeout Handling<a class="headerlink" href="#timeout-handling" title="Permanent link">&para;</a></h3>
<p>The <code>experiments_pipeline.py</code> script sets a 1-hour subprocess timeout for each benchmark. Individual Z3 verification calls timeout at 10 seconds, while optimization calls timeout at 100 seconds.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../examples/" class="btn btn-neutral float-left" title="Examples"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../postprocessors/" class="btn btn-neutral float-right" title="Postprocessors">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>Copyright &copy; 2025 Debargha Ganguly</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/debarghaG/proofofthought" class="fa fa-code-fork" style="color: #fcfcfc"> debarghaG/proofofthought</a>
        </span>
    
    
      <span><a href="../examples/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../postprocessors/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
